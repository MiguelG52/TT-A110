{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fast-langdetect wordsegment fastapi gpt4all\n",
    "# Entorno tt_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALACIONES PARA NUEVO AMBIENTE\n",
    "# %pip install wordsegment\n",
    "# %pip install transformers datasets torch pandas scikit-learn\n",
    "# %pip install sentencepiece\n",
    "# %pip install protobuf\n",
    "# %pip install ipywidgets\n",
    "# %pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL\n",
    "\n",
    "En esta sección debido al desorden se empieza a trabajar en el modelo para sugerir el nombre de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# file_path = \"./dataset/java_dataset.csv\"\n",
    "# df = pd.read_csv(file_path, encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    # T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "El CSV debe contener 'code' y 'suggested_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Asegurar que las columnas clave existen\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns, (\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl CSV debe contener \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuggested_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 2. Tokenización con CodeT5\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# tokenizer = T5Tokenizer.from_pretrained(\"Salesforce/codet5-small\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RobertaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/codet5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: El CSV debe contener 'code' y 'suggested_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    # T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# 1. Cargar el dataset desde un archivo CSV\n",
    "file_path = \"./dataset/dataset_final.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# Asegurar que las columnas clave existen\n",
    "assert \"code\" in df.columns and \"suggested_name\" in df.columns, (\n",
    "    \"El CSV debe contener 'code' y 'suggested_name'\"\n",
    ")\n",
    "\n",
    "# 2. Tokenización con CodeT5\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    \"\"\"Función para tokenizar código y nombres sugeridos\"\"\"\n",
    "    inputs = [f\"Generate name: {code}\" for code in examples[\"code\"]]\n",
    "    targets = examples[\"suggested_name\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(targets, max_length=20, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Convertir DataFrame a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Aplicar tokenización al dataset\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# 3. Dividir en train/test\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset, test_dataset = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# 4. Cargar el modelo CodeT5\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "# # 5. Configurar entrenamiento\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./codet5-fine-tuned\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "#     save_total_limit=2,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# # 6. Entrenar el modelo\n",
    "# trainer.train()\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"./codet5-fine-tuned/checkpoint-28122\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codet5-fine-tuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    resume_from_checkpoint=True,  # Habilitar reanudación\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)  # Reanuda desde el último checkpoint\n",
    "\n",
    "# 7. Guardar el modelo\n",
    "model.save_pretrained(\"./codet5-fine-tuned\")\n",
    "tokenizer.save_pretrained(\"./codet5-fine-tuned\")\n",
    "\n",
    "# print(\"¡Entrenamiento completado y modelo guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "text = \"def greet(user): print(f'hello <extra_id_0>!')\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# simply generate a single sequence\n",
    "generated_ids = model.generate(input_ids, max_length=10)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "# this prints \"user: {user.name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from wordsegment import load, segment\n",
    "\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_datos = [\n",
    "    \"boolean\",\n",
    "    \"char\",\n",
    "    \"byte\",\n",
    "    \"short\",\n",
    "    \"int\",\n",
    "    \"long\",\n",
    "    \"float\",\n",
    "    \"double\",\n",
    "    \"String\",\n",
    "    \"Array\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    package com.hmkcode;\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "\n",
    "public class textfilereader {\n",
    "\n",
    "\tprivate BufferedReader buffer;\n",
    "\tprivate String currentLine = \"\";\n",
    "\tpublic textfilereader(){ \n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic void open(String file){\n",
    "\t\t\n",
    "\t\ttry {\n",
    "\t\t\tclose();\n",
    "\t\t\t\n",
    "\t\t\tbuffer = new BufferedReader(new FileReader(file));\n",
    "\t\t\t\n",
    "\t\t} catch (FileNotFoundException e1) {\n",
    "\t\t\te1.printStackTrace();\n",
    "\t\n",
    "\t\t}\n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic void close(){\n",
    "\t\t\n",
    "\t\ttry {\n",
    "\t\t\tif(buffer != null){\n",
    "\t\t\t\tbuffer.close();\n",
    "\t\t\t\tbuffer = null;\n",
    "\t\t\t}\n",
    "\t\t} catch (IOException e) {\n",
    "\t\t\te.printStackTrace();\n",
    "\t\t}\n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic String readLine() throws Exception{\n",
    "\t\tif(buffer != null){\n",
    "\t\t\tcurrentLine = buffer.readLine();\n",
    "\t\t\t\n",
    "\t\t\tif(currentLine == null)\n",
    "\t\t\t\tclose();\n",
    "\t\t\t\n",
    "\t\t\treturn currentLine;\n",
    "\t\t}\n",
    "\t\telse\n",
    "\t\t\tthrow new Exception(\"No file to read...\");\n",
    "\t}\n",
    "\t\n",
    "\tpublic String getCurrent(){\n",
    "\t\treturn this.currentLine;\n",
    "\t}\n",
    "\t\n",
    "\tpublic boolean isReadable(){\n",
    "\t\treturn (buffer != null && this.currentLine != null);\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaración de regex para uso general\n",
    "class_starter = r\"(class)\\s([^\\{]+)\\{\"\n",
    "funciones_static = r\"(static\\s){1,1}.{0,}(){1,1}\"\n",
    "funciones_private = r\"(private\\s){1,1}.{0,}(){1,1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_coin = re.findall(pattern=class_starter, string=text)\n",
    "class_coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el nombramiento de la clase\n",
    "if bool(class_coin):\n",
    "    # Con una expresión regular verificamos el nombramiento de la clase y su respectivo nombre\n",
    "    identificador = class_coin[0][0].strip()\n",
    "\n",
    "    t_t = text.split(\"\\n\")\n",
    "    n = len(t_t)\n",
    "\n",
    "    # Iteramos por cada linea de código hasta que terminamos con el proceso de cambiar el nombre de la clase por la forma de cammel case\n",
    "    for i in range(n):\n",
    "        if identificador in t_t[i]:\n",
    "            sep_l = t_t[i].split()\n",
    "            n_2 = len(sep_l)\n",
    "            for j in range(n_2):\n",
    "                if sep_l[j] != identificador and sep_l[j] != \"public\":\n",
    "                    sep_l[j] = separate_words(sep_l[j])\n",
    "                    break\n",
    "            sep_l = \" \".join(sep_l)\n",
    "            t_t[i] = sep_l\n",
    "text = \"\\n\".join(t_t)\n",
    "\n",
    "# De momento solo se revisa si hay nombramiento de metodos privados\n",
    "if \"private\" in text:\n",
    "    coincidencias = re.findall(pattern=funciones_private, string=text)\n",
    "\n",
    "    if bool(coincidencias):\n",
    "        # print(\"segundo if\")\n",
    "        c = coincidencias[0][0].strip()\n",
    "        t_l = text.split(\"\\n\")\n",
    "        for i in range(len(t_l)):\n",
    "            # print(c,line)\n",
    "            if c in t_l[i]:\n",
    "                # print(\"antes del title\", t_l[i].strip())\n",
    "                sep = t_l[i].split()\n",
    "                # print(sep.index(c))\n",
    "                for j in range(len(sep)):\n",
    "                    if sep[j] != c and sep[j] not in tipo_datos:\n",
    "                        sep[j] = separate_words(sep[j])\n",
    "                        break\n",
    "                sep = \" \".join(sep)\n",
    "                t_l[i] = sep\n",
    "text = \"\\n\".join(t_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtb_code = \"\"\"\n",
    "import java.sql.Connection;\n",
    "import java.sql.DriverManager;\n",
    "import java.sql.ResultSet;\n",
    "import java.sql.SQLException;\n",
    "import java.sql.Statement;\n",
    "\n",
    "public class DatabaseConnection {\n",
    "    private static final String URL = \"jdbc:mysql://localhost:3306/tu_base_de_datos\";\n",
    "    private static final String USER = \"tu_usuario\";\n",
    "    private static final String PASSWORD = \"tu_contraseña\";\n",
    "\n",
    "    private Connection connection;\n",
    "\n",
    "    public DatabaseConnection() {\n",
    "        try {\n",
    "            // Cargar el driver de MySQL\n",
    "            Class.forName(\"com.mysql.cj.jdbc.Driver\");\n",
    "            // Establecer la conexión\n",
    "            connection = DriverManager.getConnection(URL, USER, PASSWORD);\n",
    "            System.out.println(\"Conexión exitosa a la base de datos.\");\n",
    "        } catch (ClassNotFoundException | SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void ejecutarConsulta(String consulta) {\n",
    "        try (Statement statement = connection.createStatement();\n",
    "             ResultSet resultSet = statement.executeQuery(consulta)) {\n",
    "            while (resultSet.next()) {\n",
    "                System.out.println(\"Resultado: \" + resultSet.getString(1));\n",
    "            }\n",
    "        } catch (SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void cerrarConexion() {\n",
    "        try {\n",
    "            if (connection != null && !connection.isClosed()) {\n",
    "                connection.close();\n",
    "                System.out.println(\"Conexión cerrada.\");\n",
    "            }\n",
    "        } catch (SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        DatabaseConnection db = new DatabaseConnection();\n",
    "        db.ejecutarConsulta(\"SELECT * FROM tu_tabla\");\n",
    "        db.cerrarConexion();\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_coin = re.findall(pattern=class_starter, string=dtb_code)\n",
    "class_coin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camell_case(word: str) -> bool:\n",
    "    \"\"\"Función para determinar si la case ya esta en formato camell case, de ser así retorna un True\n",
    "\n",
    "    Args:\n",
    "        word (str): Nombre de la clase o el método\n",
    "\n",
    "    Returns:\n",
    "        bool: Valor booleano acorde a si es cammel case o no\n",
    "    \"\"\"\n",
    "    word = word.strip()\n",
    "\n",
    "    sep = segment(word)\n",
    "\n",
    "    final = \"\".join([item.capitalize() for item in sep])\n",
    "\n",
    "    if final.strip() == word:\n",
    "        return True\n",
    "    elif final.strip() != word:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_camell_case(class_coin[0][1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "llm = GPT4All(\n",
    "    model_name=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "    model_path=\"./models\",\n",
    "    verbose=True,\n",
    "    allow_download=False,\n",
    ")\n",
    "\n",
    "with llm.chat_session():\n",
    "    print(\n",
    "        llm.generate(\n",
    "            f\"Dime si este código de java cumple con las buenas prácticas de nombramiento del libro de clean code de Robert C. Martin: {dtb_code}, si las variables no cumplen con ser lo suficientemente descriptivas, retorna un diccionario de python donde las llaves sean los nombres de las variables actuales y el valor sea el nuevo nombre. No me expliques nada, devuelve unicamente el diccionario sin dar explicaciones ni agregar ni un comentario\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    # T5Tokenizer,\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# 1. Cargar el dataset desde el archivo CSV\n",
    "df = pd.read_csv(\"./dataset/dataset_final.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Se cambia el valor para trabajar con el\n",
    "df[\"is_correct\"] = df[\"is_correct\"].astype(str)\n",
    "\n",
    "df = df.dropna()  # Se eliminan 4 nulos, que son muy pocos comparados con los demás\n",
    "\n",
    "# Asegurar que las columnas clave existen\n",
    "assert (\n",
    "    \"code\" in df.columns\n",
    "    and \"suggested_name\" in df.columns\n",
    "    and \"type\" in df.columns\n",
    "    and \"is_correct\" in df.columns\n",
    "), \"El CSV debe contener 'code', 'suggested_name', 'type' e 'is_correct'\"\n",
    "\n",
    "# 2. Tokenización con CodeT5\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "# def preprocess_data(examples):\n",
    "#     \"\"\"Función para tokenizar código y nombres sugeridos con tipo y corrección\"\"\"\n",
    "#     inputs = [\n",
    "#         f\"Generate name [type: {typ}, correct: {corr}]: {code}\"\n",
    "#         for typ, corr, code in zip(\n",
    "#             examples[\"type\"], examples[\"is_correct\"], examples[\"code\"]\n",
    "#         )\n",
    "#     ]\n",
    "#     targets = examples[\"suggested_name\"]\n",
    "\n",
    "#     model_inputs = tokenizer(\n",
    "#         inputs, max_length=512, truncation=True, padding=\"max_length\"\n",
    "#     )\n",
    "#     labels = tokenizer(targets, max_length=20, truncation=True, padding=\"max_length\")\n",
    "\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "\n",
    "# # Convertir DataFrame a Dataset de Hugging Face\n",
    "# dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# # Aplicar tokenización al dataset\n",
    "# tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# # 3. Dividir en train/test\n",
    "# split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "# train_dataset, test_dataset = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# # 4. Cargar el modelo CodeT5\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "# # 5. Configurar entrenamiento\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./codet5-fine-tuned\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "#     save_total_limit=2,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# # 6. Entrenar el modelo\n",
    "# trainer.train()\n",
    "\n",
    "# # 7. Guardar el modelo\n",
    "# model.save_pretrained(\"./codet5-fine-tuned\")\n",
    "# tokenizer.save_pretrained(\"./codet5-fine-tuned\")\n",
    "\n",
    "# print(\"¡Entrenamiento completado y modelo guardado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_correct\"] = df[\"is_correct\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())  # Verifica cuántos valores nulos hay por columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()  # Elimina filas con valores nulos\n",
    "# O\n",
    "# df = df.fillna(\"\")  # Reemplaza nulos con una cadena vacía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 83322/83322 [16:12<00:00, 85.65 examples/s] \n",
      "d:\\Users\\rod_e\\miniconda3\\envs\\tt_env\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\rod_e\\AppData\\Local\\Temp\\ipykernel_17244\\1112393671.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46870' max='46870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46870/46870 84:04:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.107727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Entrenamiento completado y modelo guardado!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,  # T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# 1. Cargar el dataset desde el archivo CSV\n",
    "df = pd.read_csv(\"./dataset/dataset_final.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Se cambia el valor para trabajar con el\n",
    "df[\"is_correct\"] = df[\"is_correct\"].astype(str)\n",
    "df = df.dropna()  # Se eliminan 4 nulos, que son muy pocos comparados con los demás\n",
    "\n",
    "# Asegurar que las columnas clave existen\n",
    "assert (\n",
    "    \"code\" in df.columns\n",
    "    and \"suggested_name\" in df.columns\n",
    "    and \"type\" in df.columns\n",
    "    and \"is_correct\" in df.columns\n",
    "), \"El CSV debe contener 'code', 'suggested_name', 'type' e 'is_correct'\"\n",
    "\n",
    "# 2. Tokenización con CodeT5\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    \"\"\"Función para tokenizar código y nombres sugeridos con tipo y corrección\"\"\"\n",
    "    inputs = [\n",
    "        f\"Generate name [type: {typ}, correct: {corr}]: {code}\"\n",
    "        for typ, corr, code in zip(\n",
    "            examples[\"type\"], examples[\"is_correct\"], examples[\"code\"]\n",
    "        )\n",
    "    ]\n",
    "    targets = examples[\"suggested_name\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(targets, max_length=20, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Convertir DataFrame a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Aplicar tokenización al dataset\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# 3. Dividir en train/test\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset, test_dataset = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# # 4. Cargar el modelo CodeT5\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "# # 5. Configurar entrenamiento\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./codet5-fine-tuned\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "#     save_total_limit=2,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# # 6. Entrenar el modelo\n",
    "# trainer.train()\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"./codet5-fine-tuned/checkpoint-28122\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codet5-fine-tuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    resume_from_checkpoint=True,  # Habilitar reanudación\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)  # Reanuda desde el último checkpoint\n",
    "\n",
    "# 7. Guardar el modelo\n",
    "model.save_pretrained(\"./codet5-fine-tuned\")\n",
    "tokenizer.save_pretrained(\"./codet5-fine-tuned\")\n",
    "\n",
    "print(\"¡Entrenamiento completado y modelo guardado!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "Parte del código para crear las predicciones en base a inputs del código Java escrito por el usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Cargar el modelo y el tokenizador desde la carpeta donde lo guardaste\n",
    "model_path = \"./codet5-fine-tuned\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suggested_name(code, type_label=\"class\", is_correct=\"true\"):\n",
    "    \"\"\"Genera un nombre sugerido para el código dado.\"\"\"\n",
    "    input_text = f\"Generate name [type: {type_label}, correct: {is_correct}]: {code}\"\n",
    "    input_ids = tokenizer(\n",
    "        input_text, return_tensors=\"pt\", max_length=512, truncation=True\n",
    "    ).input_ids\n",
    "\n",
    "    # Generar la predicción\n",
    "    output_ids = model.generate(input_ids, max_length=20, num_return_sequences=1)\n",
    "    suggested_name = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return suggested_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\" \n",
    "public class Jadx {\n",
    "\tprivate static final Logger LOG = LoggerFactory.getLogger(Jadx.class);\n",
    "\n",
    "\tprivate Jadx() {\n",
    "\t}\n",
    "\n",
    "\tpublic static List<IDexTreeVisitor> getPassesList(JadxArgs args) {\n",
    "\t\tswitch (args.getDecompilationMode()) {\n",
    "\t\t\tcase AUTO:\n",
    "\t\t\tcase RESTRUCTURE:\n",
    "\t\t\t\treturn getRegionsModePasses(args);\n",
    "\t\t\tcase SIMPLE:\n",
    "\t\t\t\treturn getSimpleModePasses(args);\n",
    "\t\t\tcase FALLBACK:\n",
    "\t\t\t\treturn getFallbackPassesList();\n",
    "\t\t\tdefault:\n",
    "\t\t\t\tthrow new JadxRuntimeException(\"Unknown decompilation mode: \" + args.getDecompilationMode());\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic static List<IDexTreeVisitor> getPreDecompilePassesList() {\n",
    "\t\tList<IDexTreeVisitor> passes = new ArrayList<>();\n",
    "\t\tpasses.add(new SignatureProcessor());\n",
    "\t\tpasses.add(new OverrideMethodVisitor());\n",
    "\t\tpasses.add(new AddAndroidConstants());\n",
    "\n",
    "\t\t// rename and deobfuscation\n",
    "\t\tpasses.add(new DeobfuscatorVisitor());\n",
    "\t\tpasses.add(new SourceFileRename());\n",
    "\t\tpasses.add(new RenameVisitor());\n",
    "\t\tpasses.add(new SaveDeobfMapping());\n",
    "\n",
    "\t\tpasses.add(new UsageInfoVisitor());\n",
    "\t\tpasses.add(new CollectConstValues());\n",
    "\t\tpasses.add(new ProcessAnonymous());\n",
    "\t\tpasses.add(new ProcessMethodsForInline());\n",
    "\t\treturn passes;\n",
    "\t}\n",
    "\n",
    "\tpublic static List<IDexTreeVisitor> getRegionsModePasses(JadxArgs args) {\n",
    "\t\tList<IDexTreeVisitor> passes = new ArrayList<>();\n",
    "\t\t// instructions IR\n",
    "\t\tpasses.add(new CheckCode());\n",
    "\t\tif (args.isDebugInfo()) {\n",
    "\t\t\tpasses.add(new DebugInfoAttachVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new AttachTryCatchVisitor());\n",
    "\t\tif (args.getCommentsLevel() != CommentsLevel.NONE) {\n",
    "\t\t\tpasses.add(new AttachCommentsVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new AttachMethodDetails());\n",
    "\t\tpasses.add(new ProcessInstructionsVisitor());\n",
    "\n",
    "\t\t// blocks IR\n",
    "\t\tpasses.add(new BlockSplitter());\n",
    "\t\tpasses.add(new BlockProcessor());\n",
    "\t\tpasses.add(new BlockFinisher());\n",
    "\t\tif (args.isRawCFGOutput()) {\n",
    "\t\t\tpasses.add(DotGraphVisitor.dumpRaw());\n",
    "\t\t}\n",
    "\n",
    "\t\tpasses.add(new SSATransform());\n",
    "\t\tpasses.add(new MoveInlineVisitor());\n",
    "\t\tpasses.add(new ConstructorVisitor());\n",
    "\t\tpasses.add(new InitCodeVariables());\n",
    "\t\tif (args.isExtractFinally()) {\n",
    "\t\t\tpasses.add(new MarkFinallyVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new ConstInlineVisitor());\n",
    "\t\tpasses.add(new TypeInferenceVisitor());\n",
    "\t\tif (args.isDebugInfo()) {\n",
    "\t\t\tpasses.add(new DebugInfoApplyVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new FixTypesVisitor());\n",
    "\t\tpasses.add(new FinishTypeInference());\n",
    "\n",
    "\t\tif (args.getUseKotlinMethodsForVarNames() != JadxArgs.UseKotlinMethodsForVarNames.DISABLE) {\n",
    "\t\t\tpasses.add(new ProcessKotlinInternals());\n",
    "\t\t}\n",
    "\t\tpasses.add(new CodeRenameVisitor());\n",
    "\t\tif (args.isInlineMethods()) {\n",
    "\t\t\tpasses.add(new InlineMethods());\n",
    "\t\t}\n",
    "\t\tpasses.add(new GenericTypesVisitor());\n",
    "\t\tpasses.add(new ShadowFieldVisitor());\n",
    "\t\tpasses.add(new DeboxingVisitor());\n",
    "\t\tpasses.add(new AnonymousClassVisitor());\n",
    "\t\tpasses.add(new ModVisitor());\n",
    "\t\tpasses.add(new CodeShrinkVisitor());\n",
    "\t\tpasses.add(new ReplaceNewArray());\n",
    "\t\tif (args.isCfgOutput()) {\n",
    "\t\t\tpasses.add(DotGraphVisitor.dump());\n",
    "\t\t}\n",
    "\n",
    "\t\t// regions IR\n",
    "\t\tpasses.add(new RegionMakerVisitor());\n",
    "\t\tpasses.add(new IfRegionVisitor());\n",
    "\t\tif (args.isRestoreSwitchOverString()) {\n",
    "\t\t\tpasses.add(new SwitchOverStringVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new ReturnVisitor());\n",
    "\t\tpasses.add(new CleanRegions());\n",
    "\n",
    "\t\tpasses.add(new CodeShrinkVisitor());\n",
    "\t\tpasses.add(new MethodInvokeVisitor());\n",
    "\t\tpasses.add(new SimplifyVisitor());\n",
    "\t\tpasses.add(new CheckRegions());\n",
    "\n",
    "\t\tpasses.add(new EnumVisitor());\n",
    "\t\tpasses.add(new FixSwitchOverEnum());\n",
    "\t\tpasses.add(new NonFinalResIdsVisitor());\n",
    "\t\tpasses.add(new ExtractFieldInit());\n",
    "\t\tpasses.add(new FixAccessModifiers());\n",
    "\t\tpasses.add(new ClassModifier());\n",
    "\t\tpasses.add(new LoopRegionVisitor());\n",
    "\n",
    "\t\tif (args.isInlineMethods()) {\n",
    "\t\t\tpasses.add(new MarkMethodsForInline());\n",
    "\t\t}\n",
    "\t\tpasses.add(new ProcessVariables());\n",
    "\t\tpasses.add(new PrepareForCodeGen());\n",
    "\t\tif (args.isCfgOutput()) {\n",
    "\t\t\tpasses.add(DotGraphVisitor.dumpRegions());\n",
    "\t\t}\n",
    "\t\treturn passes;\n",
    "\t}\n",
    "\n",
    "\tpublic static List<IDexTreeVisitor> getSimpleModePasses(JadxArgs args) {\n",
    "\t\tList<IDexTreeVisitor> passes = new ArrayList<>();\n",
    "\t\tif (args.isDebugInfo()) {\n",
    "\t\t\tpasses.add(new DebugInfoAttachVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new AttachTryCatchVisitor());\n",
    "\t\tif (args.getCommentsLevel() != CommentsLevel.NONE) {\n",
    "\t\t\tpasses.add(new AttachCommentsVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new AttachMethodDetails());\n",
    "\t\tpasses.add(new ProcessInstructionsVisitor());\n",
    "\n",
    "\t\tpasses.add(new BlockSplitter());\n",
    "\t\tif (args.isRawCFGOutput()) {\n",
    "\t\t\tpasses.add(DotGraphVisitor.dumpRaw());\n",
    "\t\t}\n",
    "\t\tpasses.add(new MethodVisitor(\"DisableBlockLock\", mth -> mth.add(AFlag.DISABLE_BLOCKS_LOCK)));\n",
    "\t\tpasses.add(new BlockProcessor());\n",
    "\t\tpasses.add(new SSATransform());\n",
    "\t\tpasses.add(new MoveInlineVisitor());\n",
    "\t\tpasses.add(new ConstructorVisitor());\n",
    "\t\tpasses.add(new InitCodeVariables());\n",
    "\t\tpasses.add(new ConstInlineVisitor());\n",
    "\t\tpasses.add(new TypeInferenceVisitor());\n",
    "\t\tif (args.isDebugInfo()) {\n",
    "\t\t\tpasses.add(new DebugInfoApplyVisitor());\n",
    "\t\t}\n",
    "\t\tpasses.add(new FixTypesVisitor());\n",
    "\t\tpasses.add(new FinishTypeInference());\n",
    "\t\tpasses.add(new CodeRenameVisitor());\n",
    "\t\tpasses.add(new DeboxingVisitor());\n",
    "\t\tpasses.add(new ModVisitor());\n",
    "\t\tpasses.add(new CodeShrinkVisitor());\n",
    "\t\tpasses.add(new ReplaceNewArray());\n",
    "\t\tpasses.add(new SimplifyVisitor());\n",
    "\t\tpasses.add(new MethodVisitor(\"ForceGenerateAll\", mth -> mth.remove(AFlag.DONT_GENERATE)));\n",
    "\t\tif (args.isCfgOutput()) {\n",
    "\t\t\tpasses.add(DotGraphVisitor.dump());\n",
    "\t\t}\n",
    "\t\treturn passes;\n",
    "\t}\n",
    "\n",
    "\tpublic static List<IDexTreeVisitor> getFallbackPassesList() {\n",
    "\t\tList<IDexTreeVisitor> passes = new ArrayList<>();\n",
    "\t\tpasses.add(new AttachTryCatchVisitor());\n",
    "\t\tpasses.add(new AttachCommentsVisitor());\n",
    "\t\tpasses.add(new ProcessInstructionsVisitor());\n",
    "\t\tpasses.add(new FallbackModeVisitor());\n",
    "\t\treturn passes;\n",
    "\t}\n",
    "\n",
    "\tpublic static final String VERSION_DEV = \"dev\";\n",
    "\n",
    "\tprivate static String version;\n",
    "\n",
    "\tpublic static String getVersion() {\n",
    "\t\tif (version == null) {\n",
    "\t\t\tversion = searchJadxVersion();\n",
    "\t\t}\n",
    "\t\treturn version;\n",
    "\t}\n",
    "\n",
    "\tpublic static boolean isDevVersion() {\n",
    "\t\treturn getVersion().equals(VERSION_DEV);\n",
    "\t}\n",
    "\n",
    "\tprivate static String searchJadxVersion() {\n",
    "\t\ttry {\n",
    "\t\t\tClassLoader classLoader = Jadx.class.getClassLoader();\n",
    "\t\t\tif (classLoader != null) {\n",
    "\t\t\t\tEnumeration<URL> resources = classLoader.getResources(\"META-INF/MANIFEST.MF\");\n",
    "\t\t\t\twhile (resources.hasMoreElements()) {\n",
    "\t\t\t\t\ttry (InputStream is = resources.nextElement().openStream()) {\n",
    "\t\t\t\t\t\tManifest manifest = new Manifest(is);\n",
    "\t\t\t\t\t\tString ver = manifest.getMainAttributes().getValue(\"jadx-version\");\n",
    "\t\t\t\t\t\tif (ver != null) {\n",
    "\t\t\t\t\t\t\treturn ver;\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t} catch (Exception e) {\n",
    "\t\t\tLOG.error(\"Can't get manifest file\", e);\n",
    "\t\t}\n",
    "\t\treturn VERSION_DEV;\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre sugerido: getDecompilationMode\n"
     ]
    }
   ],
   "source": [
    "# Hacer la predicción para un nombre de clase\n",
    "predicted_name = generate_suggested_name(code, type_label=\"class\")\n",
    "print(\"Nombre sugerido:\", predicted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>suggested_name</th>\n",
       "      <th>type</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public class ListManager {\\n    \\n    public s...</td>\n",
       "      <td>ListManager</td>\n",
       "      <td>Clase</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public class Main {\\n    \\n    public static v...</td>\n",
       "      <td>Main</td>\n",
       "      <td>Clase</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public class Main {\\n    \\n    public static v...</td>\n",
       "      <td>CustomLinkedList</td>\n",
       "      <td>Clase</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public class Main {\\n    \\n    public static v...</td>\n",
       "      <td>MyList</td>\n",
       "      <td>Clase</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public class Main {\\n    \\n    public static v...</td>\n",
       "      <td>appendToEnd</td>\n",
       "      <td>Clase</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code    suggested_name   type  \\\n",
       "0  public class ListManager {\\n    \\n    public s...       ListManager  Clase   \n",
       "1  public class Main {\\n    \\n    public static v...              Main  Clase   \n",
       "2  public class Main {\\n    \\n    public static v...  CustomLinkedList  Clase   \n",
       "3  public class Main {\\n    \\n    public static v...            MyList  Clase   \n",
       "4  public class Main {\\n    \\n    public static v...       appendToEnd  Clase   \n",
       "\n",
       "   is_correct  \n",
       "0        True  \n",
       "1       False  \n",
       "2        True  \n",
       "3       False  \n",
       "4        True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./dataset/dataset_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Clase', 'Métodos', 'Variables'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[\"type\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre sugerido: getNormalizedModePasses\n"
     ]
    }
   ],
   "source": [
    "# Hacer la predicción para un nombre de clase\n",
    "predicted_name = generate_suggested_name(code, type_label=\"Métodos\")\n",
    "print(\"Nombre sugerido:\", predicted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre sugerido: getDecompilationMode\n"
     ]
    }
   ],
   "source": [
    "# Hacer la predicción para un nombre de clase\n",
    "predicted_name = generate_suggested_name(code, type_label=\"Variables\")\n",
    "print(\"Nombre sugerido:\", predicted_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
