{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fast-langdetect wordsegment fastapi gpt4all\n",
    "# Entorno tt_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALACIONES PARA NUEVO AMBIENTE\n",
    "# %pip install wordsegment\n",
    "# %pip install transformers datasets torch pandas scikit-learn\n",
    "# %pip install sentencepiece\n",
    "# %pip install protobuf\n",
    "# %pip install ipywidgets\n",
    "# %pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL\n",
    "\n",
    "En esta sección debido al desorden se empieza a trabajar en el modelo para sugerir el nombre de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# file_path = \"./dataset/java_dataset.csv\"\n",
    "# df = pd.read_csv(file_path, encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372c22c534ba45f194083418a324c59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/miniconda3/envs/tt_env/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_9098/3050600087.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='4550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  16/4550 05:47 < 31:17:36, 0.04 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    # T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# 1. Cargar el dataset desde un archivo CSV\n",
    "file_path = \"./dataset/java_dataset.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"latin-1\")\n",
    "\n",
    "# Asegurar que las columnas clave existen\n",
    "assert \"code\" in df.columns and \"suggested_name\" in df.columns, (\n",
    "    \"El CSV debe contener 'code' y 'suggested_name'\"\n",
    ")\n",
    "\n",
    "# 2. Tokenización con CodeT5\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    \"\"\"Función para tokenizar código y nombres sugeridos\"\"\"\n",
    "    inputs = [f\"Generate name: {code}\" for code in examples[\"code\"]]\n",
    "    targets = examples[\"suggested_name\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(targets, max_length=20, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Convertir DataFrame a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Aplicar tokenización al dataset\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# 3. Dividir en train/test\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset, test_dataset = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# 4. Cargar el modelo CodeT5\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "\n",
    "# 5. Configurar entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codet5-fine-tuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 6. Entrenar el modelo\n",
    "trainer.train()\n",
    "\n",
    "# 7. Guardar el modelo\n",
    "model.save_pretrained(\"./codet5-fine-tuned\")\n",
    "tokenizer.save_pretrained(\"./codet5-fine-tuned\")\n",
    "\n",
    "# print(\"¡Entrenamiento completado y modelo guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "text = \"def greet(user): print(f'hello <extra_id_0>!')\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# simply generate a single sequence\n",
    "generated_ids = model.generate(input_ids, max_length=10)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "# this prints \"user: {user.name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from wordsegment import load, segment\n",
    "\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_datos = [\n",
    "    \"boolean\",\n",
    "    \"char\",\n",
    "    \"byte\",\n",
    "    \"short\",\n",
    "    \"int\",\n",
    "    \"long\",\n",
    "    \"float\",\n",
    "    \"double\",\n",
    "    \"String\",\n",
    "    \"Array\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    package com.hmkcode;\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "\n",
    "public class textfilereader {\n",
    "\n",
    "\tprivate BufferedReader buffer;\n",
    "\tprivate String currentLine = \"\";\n",
    "\tpublic textfilereader(){ \n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic void open(String file){\n",
    "\t\t\n",
    "\t\ttry {\n",
    "\t\t\tclose();\n",
    "\t\t\t\n",
    "\t\t\tbuffer = new BufferedReader(new FileReader(file));\n",
    "\t\t\t\n",
    "\t\t} catch (FileNotFoundException e1) {\n",
    "\t\t\te1.printStackTrace();\n",
    "\t\n",
    "\t\t}\n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic void close(){\n",
    "\t\t\n",
    "\t\ttry {\n",
    "\t\t\tif(buffer != null){\n",
    "\t\t\t\tbuffer.close();\n",
    "\t\t\t\tbuffer = null;\n",
    "\t\t\t}\n",
    "\t\t} catch (IOException e) {\n",
    "\t\t\te.printStackTrace();\n",
    "\t\t}\n",
    "\t\t\n",
    "\t}\n",
    "\t\n",
    "\tpublic String readLine() throws Exception{\n",
    "\t\tif(buffer != null){\n",
    "\t\t\tcurrentLine = buffer.readLine();\n",
    "\t\t\t\n",
    "\t\t\tif(currentLine == null)\n",
    "\t\t\t\tclose();\n",
    "\t\t\t\n",
    "\t\t\treturn currentLine;\n",
    "\t\t}\n",
    "\t\telse\n",
    "\t\t\tthrow new Exception(\"No file to read...\");\n",
    "\t}\n",
    "\t\n",
    "\tpublic String getCurrent(){\n",
    "\t\treturn this.currentLine;\n",
    "\t}\n",
    "\t\n",
    "\tpublic boolean isReadable(){\n",
    "\t\treturn (buffer != null && this.currentLine != null);\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaración de regex para uso general\n",
    "class_starter = r\"(class)\\s([^\\{]+)\\{\"\n",
    "funciones_static = r\"(static\\s){1,1}.{0,}(){1,1}\"\n",
    "funciones_private = r\"(private\\s){1,1}.{0,}(){1,1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_coin = re.findall(pattern=class_starter, string=text)\n",
    "class_coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el nombramiento de la clase\n",
    "if bool(class_coin):\n",
    "    # Con una expresión regular verificamos el nombramiento de la clase y su respectivo nombre\n",
    "    identificador = class_coin[0][0].strip()\n",
    "\n",
    "    t_t = text.split(\"\\n\")\n",
    "    n = len(t_t)\n",
    "\n",
    "    # Iteramos por cada linea de código hasta que terminamos con el proceso de cambiar el nombre de la clase por la forma de cammel case\n",
    "    for i in range(n):\n",
    "        if identificador in t_t[i]:\n",
    "            sep_l = t_t[i].split()\n",
    "            n_2 = len(sep_l)\n",
    "            for j in range(n_2):\n",
    "                if sep_l[j] != identificador and sep_l[j] != \"public\":\n",
    "                    sep_l[j] = separate_words(sep_l[j])\n",
    "                    break\n",
    "            sep_l = \" \".join(sep_l)\n",
    "            t_t[i] = sep_l\n",
    "text = \"\\n\".join(t_t)\n",
    "\n",
    "# De momento solo se revisa si hay nombramiento de metodos privados\n",
    "if \"private\" in text:\n",
    "    coincidencias = re.findall(pattern=funciones_private, string=text)\n",
    "\n",
    "    if bool(coincidencias):\n",
    "        # print(\"segundo if\")\n",
    "        c = coincidencias[0][0].strip()\n",
    "        t_l = text.split(\"\\n\")\n",
    "        for i in range(len(t_l)):\n",
    "            # print(c,line)\n",
    "            if c in t_l[i]:\n",
    "                # print(\"antes del title\", t_l[i].strip())\n",
    "                sep = t_l[i].split()\n",
    "                # print(sep.index(c))\n",
    "                for j in range(len(sep)):\n",
    "                    if sep[j] != c and sep[j] not in tipo_datos:\n",
    "                        sep[j] = separate_words(sep[j])\n",
    "                        break\n",
    "                sep = \" \".join(sep)\n",
    "                t_l[i] = sep\n",
    "text = \"\\n\".join(t_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtb_code = \"\"\"\n",
    "import java.sql.Connection;\n",
    "import java.sql.DriverManager;\n",
    "import java.sql.ResultSet;\n",
    "import java.sql.SQLException;\n",
    "import java.sql.Statement;\n",
    "\n",
    "public class DatabaseConnection {\n",
    "    private static final String URL = \"jdbc:mysql://localhost:3306/tu_base_de_datos\";\n",
    "    private static final String USER = \"tu_usuario\";\n",
    "    private static final String PASSWORD = \"tu_contraseña\";\n",
    "\n",
    "    private Connection connection;\n",
    "\n",
    "    public DatabaseConnection() {\n",
    "        try {\n",
    "            // Cargar el driver de MySQL\n",
    "            Class.forName(\"com.mysql.cj.jdbc.Driver\");\n",
    "            // Establecer la conexión\n",
    "            connection = DriverManager.getConnection(URL, USER, PASSWORD);\n",
    "            System.out.println(\"Conexión exitosa a la base de datos.\");\n",
    "        } catch (ClassNotFoundException | SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void ejecutarConsulta(String consulta) {\n",
    "        try (Statement statement = connection.createStatement();\n",
    "             ResultSet resultSet = statement.executeQuery(consulta)) {\n",
    "            while (resultSet.next()) {\n",
    "                System.out.println(\"Resultado: \" + resultSet.getString(1));\n",
    "            }\n",
    "        } catch (SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void cerrarConexion() {\n",
    "        try {\n",
    "            if (connection != null && !connection.isClosed()) {\n",
    "                connection.close();\n",
    "                System.out.println(\"Conexión cerrada.\");\n",
    "            }\n",
    "        } catch (SQLException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        DatabaseConnection db = new DatabaseConnection();\n",
    "        db.ejecutarConsulta(\"SELECT * FROM tu_tabla\");\n",
    "        db.cerrarConexion();\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_coin = re.findall(pattern=class_starter, string=dtb_code)\n",
    "class_coin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camell_case(word: str) -> bool:\n",
    "    \"\"\"Función para determinar si la case ya esta en formato camell case, de ser así retorna un True\n",
    "\n",
    "    Args:\n",
    "        word (str): Nombre de la clase o el método\n",
    "\n",
    "    Returns:\n",
    "        bool: Valor booleano acorde a si es cammel case o no\n",
    "    \"\"\"\n",
    "    word = word.strip()\n",
    "\n",
    "    sep = segment(word)\n",
    "\n",
    "    final = \"\".join([item.capitalize() for item in sep])\n",
    "\n",
    "    if final.strip() == word:\n",
    "        return True\n",
    "    elif final.strip() != word:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_camell_case(class_coin[0][1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "llm = GPT4All(\n",
    "    model_name=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "    model_path=\"./models\",\n",
    "    verbose=True,\n",
    "    allow_download=False,\n",
    ")\n",
    "\n",
    "with llm.chat_session():\n",
    "    print(\n",
    "        llm.generate(\n",
    "            f\"Dime si este código de java cumple con las buenas prácticas de nombramiento del libro de clean code de Robert C. Martin: {dtb_code}, si las variables no cumplen con ser lo suficientemente descriptivas, retorna un diccionario de python donde las llaves sean los nombres de las variables actuales y el valor sea el nuevo nombre. No me expliques nada, devuelve unicamente el diccionario sin dar explicaciones ni agregar ni un comentario\"\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
